{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression on the World Population\n",
    "© Explore Data Science Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this coding challenge, we'll learn how decision trees can be expanded upon as simple regressors in order to create an [ensemble](https://en.wikipedia.org/wiki/Ensemble_learning) model know as a Random Forest. For this coding challenges, we train the model using the world population data. \n",
    "\n",
    "<img src=\"https://github.com/Explore-AI/Pictures/blob/master/population.png?raw=true\" width=70%/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Honour Code\n",
    "\n",
    "I **Bruce, Kgarimetsa**, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the EDSA honour code (https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import array\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/AnalyseProject/world_population.csv', index_col='Country Code')\n",
    "meta_df = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/AnalyseProject/metadata.csv', index_col='Country Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>1967</th>\n",
       "      <th>1968</th>\n",
       "      <th>1969</th>\n",
       "      <th>...</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country Code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ABW</th>\n",
       "      <td>54211.0</td>\n",
       "      <td>55438.0</td>\n",
       "      <td>56225.0</td>\n",
       "      <td>56695.0</td>\n",
       "      <td>57032.0</td>\n",
       "      <td>57360.0</td>\n",
       "      <td>57715.0</td>\n",
       "      <td>58055.0</td>\n",
       "      <td>58386.0</td>\n",
       "      <td>58726.0</td>\n",
       "      <td>...</td>\n",
       "      <td>101353.0</td>\n",
       "      <td>101453.0</td>\n",
       "      <td>101669.0</td>\n",
       "      <td>102053.0</td>\n",
       "      <td>102577.0</td>\n",
       "      <td>103187.0</td>\n",
       "      <td>103795.0</td>\n",
       "      <td>104341.0</td>\n",
       "      <td>104822.0</td>\n",
       "      <td>105264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFG</th>\n",
       "      <td>8996351.0</td>\n",
       "      <td>9166764.0</td>\n",
       "      <td>9345868.0</td>\n",
       "      <td>9533954.0</td>\n",
       "      <td>9731361.0</td>\n",
       "      <td>9938414.0</td>\n",
       "      <td>10152331.0</td>\n",
       "      <td>10372630.0</td>\n",
       "      <td>10604346.0</td>\n",
       "      <td>10854428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27294031.0</td>\n",
       "      <td>28004331.0</td>\n",
       "      <td>28803167.0</td>\n",
       "      <td>29708599.0</td>\n",
       "      <td>30696958.0</td>\n",
       "      <td>31731688.0</td>\n",
       "      <td>32758020.0</td>\n",
       "      <td>33736494.0</td>\n",
       "      <td>34656032.0</td>\n",
       "      <td>35530081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGO</th>\n",
       "      <td>5643182.0</td>\n",
       "      <td>5753024.0</td>\n",
       "      <td>5866061.0</td>\n",
       "      <td>5980417.0</td>\n",
       "      <td>6093321.0</td>\n",
       "      <td>6203299.0</td>\n",
       "      <td>6309770.0</td>\n",
       "      <td>6414995.0</td>\n",
       "      <td>6523791.0</td>\n",
       "      <td>6642632.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21759420.0</td>\n",
       "      <td>22549547.0</td>\n",
       "      <td>23369131.0</td>\n",
       "      <td>24218565.0</td>\n",
       "      <td>25096150.0</td>\n",
       "      <td>25998340.0</td>\n",
       "      <td>26920466.0</td>\n",
       "      <td>27859305.0</td>\n",
       "      <td>28813463.0</td>\n",
       "      <td>29784193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALB</th>\n",
       "      <td>1608800.0</td>\n",
       "      <td>1659800.0</td>\n",
       "      <td>1711319.0</td>\n",
       "      <td>1762621.0</td>\n",
       "      <td>1814135.0</td>\n",
       "      <td>1864791.0</td>\n",
       "      <td>1914573.0</td>\n",
       "      <td>1965598.0</td>\n",
       "      <td>2022272.0</td>\n",
       "      <td>2081695.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2947314.0</td>\n",
       "      <td>2927519.0</td>\n",
       "      <td>2913021.0</td>\n",
       "      <td>2905195.0</td>\n",
       "      <td>2900401.0</td>\n",
       "      <td>2895092.0</td>\n",
       "      <td>2889104.0</td>\n",
       "      <td>2880703.0</td>\n",
       "      <td>2876101.0</td>\n",
       "      <td>2873457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AND</th>\n",
       "      <td>13411.0</td>\n",
       "      <td>14375.0</td>\n",
       "      <td>15370.0</td>\n",
       "      <td>16412.0</td>\n",
       "      <td>17469.0</td>\n",
       "      <td>18549.0</td>\n",
       "      <td>19647.0</td>\n",
       "      <td>20758.0</td>\n",
       "      <td>21890.0</td>\n",
       "      <td>23058.0</td>\n",
       "      <td>...</td>\n",
       "      <td>83861.0</td>\n",
       "      <td>84462.0</td>\n",
       "      <td>84449.0</td>\n",
       "      <td>83751.0</td>\n",
       "      <td>82431.0</td>\n",
       "      <td>80788.0</td>\n",
       "      <td>79223.0</td>\n",
       "      <td>78014.0</td>\n",
       "      <td>77281.0</td>\n",
       "      <td>76965.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   1960       1961       1962       1963       1964  \\\n",
       "Country Code                                                          \n",
       "ABW             54211.0    55438.0    56225.0    56695.0    57032.0   \n",
       "AFG           8996351.0  9166764.0  9345868.0  9533954.0  9731361.0   \n",
       "AGO           5643182.0  5753024.0  5866061.0  5980417.0  6093321.0   \n",
       "ALB           1608800.0  1659800.0  1711319.0  1762621.0  1814135.0   \n",
       "AND             13411.0    14375.0    15370.0    16412.0    17469.0   \n",
       "\n",
       "                   1965        1966        1967        1968        1969  ...  \\\n",
       "Country Code                                                             ...   \n",
       "ABW             57360.0     57715.0     58055.0     58386.0     58726.0  ...   \n",
       "AFG           9938414.0  10152331.0  10372630.0  10604346.0  10854428.0  ...   \n",
       "AGO           6203299.0   6309770.0   6414995.0   6523791.0   6642632.0  ...   \n",
       "ALB           1864791.0   1914573.0   1965598.0   2022272.0   2081695.0  ...   \n",
       "AND             18549.0     19647.0     20758.0     21890.0     23058.0  ...   \n",
       "\n",
       "                    2008        2009        2010        2011        2012  \\\n",
       "Country Code                                                               \n",
       "ABW             101353.0    101453.0    101669.0    102053.0    102577.0   \n",
       "AFG           27294031.0  28004331.0  28803167.0  29708599.0  30696958.0   \n",
       "AGO           21759420.0  22549547.0  23369131.0  24218565.0  25096150.0   \n",
       "ALB            2947314.0   2927519.0   2913021.0   2905195.0   2900401.0   \n",
       "AND              83861.0     84462.0     84449.0     83751.0     82431.0   \n",
       "\n",
       "                    2013        2014        2015        2016        2017  \n",
       "Country Code                                                              \n",
       "ABW             103187.0    103795.0    104341.0    104822.0    105264.0  \n",
       "AFG           31731688.0  32758020.0  33736494.0  34656032.0  35530081.0  \n",
       "AGO           25998340.0  26920466.0  27859305.0  28813463.0  29784193.0  \n",
       "ALB            2895092.0   2889104.0   2880703.0   2876101.0   2873457.0  \n",
       "AND              80788.0     79223.0     78014.0     77281.0     76965.0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Income Group</th>\n",
       "      <th>Special Notes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country Code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ABW</th>\n",
       "      <td>Latin America &amp; Caribbean</td>\n",
       "      <td>High income</td>\n",
       "      <td>Mining is included in agriculture\\r\\r\\r\\nElect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFG</th>\n",
       "      <td>South Asia</td>\n",
       "      <td>Low income</td>\n",
       "      <td>Fiscal year end: March 20; reporting period fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGO</th>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>Lower middle income</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALB</th>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "      <td>Upper middle income</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AND</th>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "      <td>High income</td>\n",
       "      <td>WB-3 code changed from ADO to AND to align wit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Region         Income Group  \\\n",
       "Country Code                                                   \n",
       "ABW           Latin America & Caribbean          High income   \n",
       "AFG                          South Asia           Low income   \n",
       "AGO                  Sub-Saharan Africa  Lower middle income   \n",
       "ALB               Europe & Central Asia  Upper middle income   \n",
       "AND               Europe & Central Asia          High income   \n",
       "\n",
       "                                                  Special Notes  \n",
       "Country Code                                                     \n",
       "ABW           Mining is included in agriculture\\r\\r\\r\\nElect...  \n",
       "AFG           Fiscal year end: March 20; reporting period fo...  \n",
       "AGO                                                         NaN  \n",
       "ALB                                                         NaN  \n",
       "AND           WB-3 code changed from ADO to AND to align wit...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've seen previously, the world population data spans from 1960 to 2017. We'd like to build a predictive model that can give us the best guess at what the world population in a given year was. However, as a slight twist this time, we want to compute this estimate for only _countries within a given income group_. \n",
    "\n",
    "First, however, we need to organise our data such that the sklearn's `RandomForestRegressor` class can train on our data. To do this, we will write a function that takes as input an income group and return a 2-d numpy array that contains the year and the measured population.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take a `str` argument, called `income_group_name` as input and return a numpy `array` type as output.\n",
    "* Set the default argument of `income_group_name` to equal `'Low income'`.\n",
    "* If the specified value of `income_group_name` does not exist, the function must raise a `ValueError`.\n",
    "* The array should only have two columns containing the year and the population, in other words, it should have a shape `(?, 2)` where `?` is the length of the data.\n",
    "* The values within the array should be of type `np.int64`. \n",
    "\n",
    "_**Further Reading:**_\n",
    "\n",
    "Data types are associated with memory allocation. As such, your choice of data type affects the precision of computations in your program. For example, the `np.int` data type in numpy can only store values between -2147483648 to 2147483647 and assigning values outside this range for variables of this data type may cause run-time errors. To avoid this, we can use data types with larger memory capacity e.g. `np.int64`.\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/user/basics.types.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def get_total_pop_by_income(income_group_name='Low income'):\n",
    "    # your code here\n",
    "    pop_copy = population_df.copy()\n",
    "    meta_copy = meta_df.copy()\n",
    "    \n",
    "    combined = pop_copy.merge(meta_copy, on='Country Code')\n",
    "    combined = combined.groupby('Income Group').sum()\n",
    "    \n",
    "    if income_group_name in combined.index:\n",
    "        years = array(combined.columns.astype(np.int64))\n",
    "        population = array(combined.loc[income_group_name]).astype(np.int64)\n",
    "        two_d_array = array([years,population])\n",
    "        \n",
    "    else:\n",
    "        raise ValueError('Income group not available')\n",
    "        \n",
    "    return np.transpose(two_d_array)    \n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f5172993\\AppData\\Local\\Temp\\ipykernel_20108\\3925851362.py:8: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  combined = combined.groupby('Income Group').sum()\n"
     ]
    }
   ],
   "source": [
    "data = get_total_pop_by_income('High income')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "```python\n",
    "get_total_pop_by_income('High income')\n",
    "```\n",
    "> ```\n",
    "array([[      1960,  769889923],\n",
    "       [      1961,  781225329],\n",
    "       [      1962,  791207437],\n",
    "       [      1963,  801108277],\n",
    "       ...\n",
    "       [      2015, 1211252041],\n",
    "       [      2016, 1218629612],\n",
    "       [      2017, 1225514228]])\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Now that we have have our data, we need to split this into a set of variables we will be training on, and the set of variables that we will make our predictions on.\n",
    "\n",
    "Unlike in the previous coding challenge, a friend of ours has indicated that sklearn has a bunch of built-in functionality for creating training and testing sets. In this case however, they have asked us to implement a k-fold cross validation split of the data using sklearn's `KFold` [class](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) (which has already been imported into this notebook for your convenience). \n",
    "\n",
    "Using this knowledge, write a function which uses sklearn's `KFold` [class](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) internally, and that will take as input a 2-d numpy array and an integer `K` corresponding to the number of splits. This function will then return a list of tuples of length `K`. Each tuple in this list should consist of a `train_indices` list and a `test_indices` list containing the training/testing data point indices for that particular K$^{th}$ split.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take a 2-d numpy `array` and an integer `K` as input.\n",
    "* Should use sklearn's `KFold` [class](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html).\n",
    "* Should return a list of `K` `tuples` containing a list of training and testing indices corresponding to the data points that belong to a particular split. For example, given an array called `data` and an integer `K`, the function should return: \n",
    ">```\n",
    "data_indices = [(list_of_train_indices_for_split_1, list_of_test_indices_for_split_1)\n",
    "                  (list_of_train_indices_for_split_2, list_of_test_indices_for_split_2)\n",
    "                  (list_of_train_indices_for_split_3, list_of_test_indices_for_split_3)\n",
    "                                                   ...\n",
    "                                                   ...\n",
    "                  (list_of_train_indices_for_split_K, list_of_test_indices_for_split_K)]\n",
    "```\n",
    "\n",
    "* The `shuffle` argument in the KFold object should be set to `False`.\n",
    "\n",
    "**_Hint_**: To see an example of how to use the `KFold` object enter `help(KFold)` in a new notebook cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def sklearn_kfold_split(data,K):\n",
    "    # your code here\n",
    "    kf = KFold(n_splits=K)\n",
    "    \n",
    "    kf.get_n_splits(data)\n",
    "    \n",
    "    data_indices = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(data):\n",
    "        data_indices.append((train_index,test_index))\n",
    "        \n",
    "    return data_indices\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f5172993\\AppData\\Local\\Temp\\ipykernel_20108\\3925851362.py:8: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  combined = combined.groupby('Income Group').sum()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array([15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,\n",
       "         32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48,\n",
       "         49, 50, 51, 52, 53, 54, 55, 56, 57]),\n",
       "  array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])),\n",
       " (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 30, 31,\n",
       "         32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48,\n",
       "         49, 50, 51, 52, 53, 54, 55, 56, 57]),\n",
       "  array([15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])),\n",
       " (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "         17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 44, 45, 46, 47,\n",
       "         48, 49, 50, 51, 52, 53, 54, 55, 56, 57]),\n",
       "  array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43])),\n",
       " (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "         17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "         34, 35, 36, 37, 38, 39, 40, 41, 42, 43]),\n",
       "  array([44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57]))]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_total_pop_by_income('High income');\n",
    "sklearn_kfold_split(data,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "```python\n",
    "data = get_total_pop_by_income('High income')\n",
    "sklearn_kfold_split(data,4)\n",
    "```\n",
    "> ```\n",
    "[(array([15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,\n",
    "         32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48,\n",
    "         49, 50, 51, 52, 53, 54, 55, 56, 57]),\n",
    "  array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])),\n",
    " (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 30, 31,\n",
    "         32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48,\n",
    "         49, 50, 51, 52, 53, 54, 55, 56, 57]),\n",
    "  array([15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])),\n",
    " (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
    "         17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 44, 45, 46, 47,\n",
    "         48, 49, 50, 51, 52, 53, 54, 55, 56, 57]),\n",
    "  array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43])),\n",
    " (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
    "         17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
    "         34, 35, 36, 37, 38, 39, 40, 41, 42, 43]),\n",
    "  array([44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57]))]\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Now that we have formatted our data, we can fit a model using sklearn's `RandomForestRegressor` class. We'll write a function that will take as input the data indices (consisting of the train and test indices for each split) that we created in the last question, train a different `RandomForestRegressor` on each split and return the model that obtains the best testing set performance across all K splits.\n",
    "\n",
    "**Important Note:** Due to the random initialisation process used within sklearn's `RandomForestRegressor` class, you will need to fix the value of the `random_state` argument in order to get repeatable and predictable results.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take a 2-d numpy array (i.e. the data) and `data_indices` (a list of `(train_indices,test_indices)` tuples) as input.\n",
    "* For each `(train_indices,test_indices)` tuple in `data_indices` the function should:\n",
    "    * Train a new `RandomForestRegressor` model on the portion of data indexed by `train_indices`\n",
    "    * Evaluate the trained `RandomForestRegressor` model on the portion of data indexed by `test_indices` using the **mean squared error** (which has also been imported for your convenience).\n",
    "* After training and evalating the `RandomForestRegressor` models, the function should return the `RandomForestRegressor` model that obtained highest testing set `mean_square_error` over its allocated data split across all trained models. \n",
    "* The trained `RandomForestRegressor` models should be trained with `random_state` equal `42`, all other parameters should be left as default.\n",
    "\n",
    "**_Hint_**: for each tuple in the `data_indices` list, you can obtain `X_train`,`X_test`, `y_train`, `y_test` as follows:  \n",
    ">```\n",
    "    X_train, y_train = data[train_indices,0],data[train_indices,1]\n",
    "    X_test, y_test = data[test_indices,0],data[test_indices,1]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def best_k_model(data,data_indices):\n",
    "     # your code here\n",
    "    mse = float('inf')\n",
    "    model = None\n",
    "    \n",
    "    for train_index, test_index in data_indices:\n",
    "        x_train, y_train = data[train_index, 0], data[train_index, 1]\n",
    "        x_test, y_test = data[test_index, 0], data[test_index, 1]\n",
    "        model2 = RandomForestRegressor(random_state = 42)\n",
    "        model2.fit(x_train, y_train)\n",
    "        y_pred = model2.predict(x_test)\n",
    "        error = mean_squared_error(y_test, y_pred)\n",
    "        \n",
    "        if error < mse:\n",
    "            mse = error\n",
    "            model = model2\n",
    "\n",
    "    return model\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f5172993\\AppData\\Local\\Temp\\ipykernel_20108\\3925851362.py:8: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  combined = combined.groupby('Income Group').sum()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1972. 1973. 1974. 1975. 1976. 1977. 1978. 1979. 1980. 1981. 1982. 1983.\n 1984. 1985. 1986. 1987. 1988. 1989. 1990. 1991. 1992. 1993. 1994. 1995.\n 1996. 1997. 1998. 1999. 2000. 2001. 2002. 2003. 2004. 2005. 2006. 2007.\n 2008. 2009. 2010. 2011. 2012. 2013. 2014. 2015. 2016. 2017.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m data \u001b[38;5;241m=\u001b[39m get_total_pop_by_income(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHigh income\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m data_indices \u001b[38;5;241m=\u001b[39m sklearn_kfold_split(data,\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mbest_k_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m best_model\u001b[38;5;241m.\u001b[39mpredict([[\u001b[38;5;241m1960\u001b[39m]])\n",
      "Cell \u001b[1;32mIn[99], line 11\u001b[0m, in \u001b[0;36mbest_k_model\u001b[1;34m(data, data_indices)\u001b[0m\n\u001b[0;32m      9\u001b[0m x_test, y_test \u001b[38;5;241m=\u001b[39m data[test_index, \u001b[38;5;241m0\u001b[39m], data[test_index, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     10\u001b[0m model2 \u001b[38;5;241m=\u001b[39m RandomForestRegressor(random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model2\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[0;32m     13\u001b[0m error \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_pred)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:345\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 345\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    349\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:902\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    901\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 902\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    903\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    904\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    905\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    906\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    907\u001b[0m         )\n\u001b[0;32m    909\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    913\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1972. 1973. 1974. 1975. 1976. 1977. 1978. 1979. 1980. 1981. 1982. 1983.\n 1984. 1985. 1986. 1987. 1988. 1989. 1990. 1991. 1992. 1993. 1994. 1995.\n 1996. 1997. 1998. 1999. 2000. 2001. 2002. 2003. 2004. 2005. 2006. 2007.\n 2008. 2009. 2010. 2011. 2012. 2013. 2014. 2015. 2016. 2017.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "data = get_total_pop_by_income('High income')\n",
    "data_indices = sklearn_kfold_split(data,5)\n",
    "\n",
    "best_model = best_k_model(data,data_indices)\n",
    "best_model.predict([[1960]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "```python\n",
    "best_model.predict([[1960]]) == array([8.85170916e+08])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f5172993\\AppData\\Local\\Temp\\ipykernel_20108\\3925851362.py:8: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  combined = combined.groupby('Income Group').sum()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1972. 1973. 1974. 1975. 1976. 1977. 1978. 1979. 1980. 1981. 1982. 1983.\n 1984. 1985. 1986. 1987. 1988. 1989. 1990. 1991. 1992. 1993. 1994. 1995.\n 1996. 1997. 1998. 1999. 2000. 2001. 2002. 2003. 2004. 2005. 2006. 2007.\n 2008. 2009. 2010. 2011. 2012. 2013. 2014. 2015. 2016. 2017.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m data \u001b[38;5;241m=\u001b[39m get_total_pop_by_income(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHigh income\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m data_indices \u001b[38;5;241m=\u001b[39m sklearn_kfold_split(data,\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mbest_k_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m best_model\u001b[38;5;241m.\u001b[39mpredict([[\u001b[38;5;241m1960\u001b[39m]]) \u001b[38;5;241m==\u001b[39m array([\u001b[38;5;241m8.85170916e+08\u001b[39m])\n",
      "Cell \u001b[1;32mIn[82], line 11\u001b[0m, in \u001b[0;36mbest_k_model\u001b[1;34m(data, data_indices)\u001b[0m\n\u001b[0;32m      9\u001b[0m x_test, y_test \u001b[38;5;241m=\u001b[39m data[test_index, \u001b[38;5;241m0\u001b[39m], data[test_index, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     10\u001b[0m model2 \u001b[38;5;241m=\u001b[39m RandomForestRegressor(random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m41\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model2\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[0;32m     13\u001b[0m error \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_pred)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:345\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 345\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    349\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:902\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    901\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 902\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    903\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    904\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    905\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    906\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    907\u001b[0m         )\n\u001b[0;32m    909\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    913\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1972. 1973. 1974. 1975. 1976. 1977. 1978. 1979. 1980. 1981. 1982. 1983.\n 1984. 1985. 1986. 1987. 1988. 1989. 1990. 1991. 1992. 1993. 1994. 1995.\n 1996. 1997. 1998. 1999. 2000. 2001. 2002. 2003. 2004. 2005. 2006. 2007.\n 2008. 2009. 2010. 2011. 2012. 2013. 2014. 2015. 2016. 2017.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "data = get_total_pop_by_income('High income')\n",
    "data_indices = sklearn_kfold_split(data,5)\n",
    "best_model = best_k_model(data,data_indices)\n",
    "best_model.predict([[1960]]) == array([8.85170916e+08])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
