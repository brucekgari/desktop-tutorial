{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Recommender Systems: Part 1\n",
    "© Explore Data Science Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "In this train you learn how to:\n",
    "- Understand the purpose and basic operation of a recommender system;\n",
    "- Understand the role of similarity metrics utilised in recommender algorithms;\n",
    "- Assess the performance of a recommender system;\n",
    "- Gain an intuition for the basic operation of content-based filtering; and \n",
    "- Implement a simple content-based filtering algorithm.\n",
    "\n",
    "## Outline\n",
    "\n",
    "This train is structured as follows:\n",
    "- The importance of making recommendations;\n",
    "- Measuring similarity; \n",
    "- Assessing the performance of a recommender system; \n",
    "- Intuition behind content-based filtering; and \n",
    "- Implementation of content-based filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Importance of Making Recommendations\n",
    "\n",
    "<br></br>\n",
    "\n",
    "<div align=\"center\" style=\"width: 600px; font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Long_tail_problem.jpg\"\n",
    "     alt=\"The Long Tail Problem\"\n",
    "     style=\"float: center; padding-bottom=0.5em\"\n",
    "     width=600px/>\n",
    "The Long tail problem often experienced by content distributors. \n",
    "</div>\n",
    "\n",
    "\n",
    "We exist in a technological era where there is far too much content (movies, news articles, shopping products, websites, etc.) for individual items to each receive our personal consideration. For example, consider that the average Google search returns well over 1 million results, yet when last did you look at the websites past the [first page](https://backlinko.com/google-ctr-stats)?  This fact is often illustrated by what is known as the \"long tail problem\" (represented in the figure above), where tracking user engagement with items in a large content repository sees a small number of these items receiving a disproportionate amount of attention, while the majority of items are unexplored. The truth is that a user simply doesn't know of each item which exists, nor has the time to inspect each item even if it were known. \n",
    "\n",
    "In light of the above challenge, a natural question for service providers becomes: \"how do I ensure that an individual is shown a manageable portion of the total content I have available, while also ensuring that this content is relevant to and desired by them?\" It turns out that this is actually an extremely valuable question, both economically and within society as a whole. Luckily for us, decades of hard work by very intelligent individuals has largely answered this question through a collection of algorithms and computing techniques known as recommender systems. \n",
    "\n",
    "\n",
    "Simply put, a recommender system functions by predicting a user's rating or preference for an item. This allows a service provider to build up a catalog of items which it believes the user will want to examine - thereby increasing their engagement with the service and allowing a wider array of content to be considered.\n",
    "\n",
    "\n",
    "Within this train, we will review some of the fundamental concepts upon which recommender systems operate. We will also learn how to create a simple implementation of one of the two dominant methods currently studied in relation to recommender systems, referred to as content-based filtering. \n",
    "\n",
    "This is going to be a lot to learn, so let's dive in!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminology: Users, Items, and Ratings  \n",
    "\n",
    "The first thing we need to do when speaking about recommender systems is to get some terminology straight. Within a recommender system, there are two primary sets of entities: the Users and the Items. \n",
    "\n",
    "As we'd expect, **an item is a thing which is consumed**. It can be watched, read, bought, clicked-on, or considered. Items are passive; meaning that their properties or nature does not change. \n",
    "\n",
    "**Users are individuals who interact with the items in a recommendation system**. Through their *actions*, **users create ratings for specific items within a recommendation system**. Ratings can be either *explicit* (such as giving your favorite movie 5/5 stars on review) or *implicit* (such as watching a movie; even though you haven't rated it directly, by viewing something you indicate that you have some interest in it). Within this train, we only consider explicit ratings, but many of the principles covered here will apply to implicit ratings as well.  \n",
    "\n",
    "A given user can have ratings for many items in the system, or none at all. Generally, as a user continues to interact with a recommender system, the more it will be able to capture her preferences and ratings for items. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Similarity \n",
    "\n",
    "<br></br>\n",
    "\n",
    "<div align=\"center\" style=\"width: 600px; font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Cosine_similarity.jpg\"\n",
    "     alt=\"Cosine Similarity \"\n",
    "     style=\"float: center; padding-bottom=0.5em\"\n",
    "     width=600px/>\n",
    "Measuring the similarity between the ratings of two users (A) and (B) for the books 'Harry Potter and the Philosopher's Stone' and 'The Diary of a Young Girl', using the Cosine similarity metric.  \n",
    "</div>\n",
    "\n",
    "\n",
    "Having learnt about the entities which exist within recommender systems, we may wonder how they function. While this is something that we'll learn throughout this entire train, one fundamental principal that we need to understand is that recommender systems are built up by utilising the _relations_ which  exist between items and users. As such, these systems always need a mechanism to measure how related or _similar_ a user is to another user, or an item is to another item. \n",
    "\n",
    "We accomplish this measurement of similarity through, you guessed it, a _similarity metric_.  \n",
    "\n",
    "Generally speaking, a similarity metric can be thought of as being the inverse of a distance measure: if two things are considered to be very similar they should be assigned a high similarity value (close to 1), while dissimilar items should receive a low similarity value (close to zero). Other [important properties](https://online.stat.psu.edu/stat508/lesson/1b/1b.2/1b.2.1) include:\n",
    " - (Symmetry) $Sim(A,B) = Sim(B,A)$ \n",
    " - (Identity) $Sim(A,A) = 1$\n",
    " - (Uniqueness) $Sim(A,B) = 1 \\leftrightarrow A = B$\n",
    " \n",
    "While there are many similarity metrics to choose from when building a recommender system (and more than one can certainly be used simultaneously), a popular choice is the **Cosine similarity**. We won't go into the fundamental trig here (we hope that you remember this from high school), but recall that as an angle becomes smaller (approaching $0^o$) the value of its cosine increases. Conversely, as the angle increases the cosine value decreases. It turns out that this behavior makes the cosine of the angle between two p-dimensional vectors desirable as a [similarity metric](https://en.wikipedia.org/wiki/Cosine_similarity) which can easily be computed.\n",
    "\n",
    "Using the figure above to help guide our understanding, the Cosine similarity between two p-dimensional vectors ${A}$ and $B$ can be given as:\n",
    "\n",
    "$$ \\begin{align}\n",
    "Sim(A,B)  &= \\frac{A \\cdot B}{||A|| \\times ||B||} \\\\ \\\\\n",
    "& = \\frac{\\sum_{i=1}^{p}A_{i}B_{i}}{\\sqrt{{\\sum_{i=1}^{p}A_{i}^2}} \\sqrt{\\sum_{i=1}^{p}B_{i}^2}}, \\\\\n",
    "\\end{align} $$ \n",
    "  \n",
    "\n",
    "To make things a little more concrete, let's work out the cosine similarity using our provided example above. Here, each vector represents the ratings given by one of two *users*, $A$ and $B$, who have each rated two books (rating#1 $ \\rightarrow r_1$, and rating#2 $ \\rightarrow r_2$). To work out how similar these two users are based on their supplied ratings, we can use the Cosine similarity definition as follows:   \n",
    "\n",
    "\n",
    "$$ \\begin{align}\n",
    "Sim(A,B)  & = \\frac{(A_{r1} \\times B_{r1})+(A_{r2} \\times B_{r2})}{\\sqrt{A_{r1}^2 + A_{r2}^2} \\times \\sqrt{B_{r1}^2 + B_{r2}^2}} \\\\ \\\\\n",
    "& = \\frac{(3 \\times 5) + (4 \\times 2)}{\\sqrt{9 + 16} \\times \\sqrt{25 + 4}} \\\\ \\\\\n",
    "& = \\frac{23}{26.93} \\\\ \\\\\n",
    "& = 0.854\n",
    "\\end{align} $$\n",
    "\n",
    "It would be a pain to work this out manually each time! Thankfully, we can obtain this same result using the `cosine_similarity` function provided to us in `sklearn`. \n",
    "\n",
    "As usual before we can go ahead and use this function we need to import the libraries that we will need.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our regular old heroes \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp # <-- The sister of Numpy, used in our code for numerical efficientcy. \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Entity featurization and similarity computation\n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Libraries used during sorting procedures.\n",
    "import operator # <-- Convienient item retrieval during iteration \n",
    "import heapq # <-- Efficient sorting of large lists\n",
    "\n",
    "# Imported for our sanity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85419856]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[3,4]]) # <-- Rating vector A\n",
    "B = np.array([[5,2]]) # <-- Rating vector B\n",
    "cosine_similarity(A,B) # Sim(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an understanding of similarity out of the way, let's look at one more important concept before creating our own simple recommender systems - performance measurement!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing the Performance of a Recommender System\n",
    "\n",
    "One more thing we need to consider before we dive into the inner workings of recommender system algorithms is the aspect of how to evaluate their performance. After all, how can you tell if a recommendation is good if the item being suggested is something you've never seen before? \n",
    "\n",
    "One straightforward approach is to use a statistical method such as [A/B testing](https://en.wikipedia.org/wiki/A/B_testing), where two very similar users are shown different recommendations; with user `A` being shown randomly selected items from our catalog, and user `B` being shown recommendations generated by our algorithm. Unfortunately, like other areas of machine learning, this strategy may be a bit too risky/expensive to let a poor recommendation system (or random recommendations!) be exposed to users. Instead, in a similar approach to other machine learning fields, we tend to make use of historical rating data collected from users to test our systems. Here, as we have seen before, we partition our historical rating data into train and test splits; using train data to help build and tune our recommendation algorithms, while test data are withheld in order to perform assessment.  \n",
    "\n",
    "In this sense, there are two main variants of metrics which we use to evaluate the predictions made by a recommender system: \n",
    "\n",
    "#### Objective Measures\n",
    "\n",
    "Objective performance measures for a recommendation system provide results which do not depend upon personal interpretation in order to assign success. These measures tend to focus around actual preference/ratings given by users to items, and are compared against ratings/preference predicted by an algorithm. Common examples of objective measures include: \n",
    "\n",
    "   - **Single-value metrics:** These are quantities which we've seen before such as RMSE and MAE which measure the error between a known and predicted rating on a continuous scale. \n",
    "    \n",
    "    \n",
    "   - **Catalog-based metrics:** These are measures of performance computed over lists of recommended items generated for a user. They mainly consist of variations surrounding what is known as the *hit-rate*, which determines the number of highly-rated items appearing in a recommendation list which the user has actually given a high rating to.    \n",
    "   \n",
    " \n",
    " - **Coverage:** This metric is calculated across multiple user recommendation lists, and returns the number of users who received at least one high-rated recommendation in their list. \n",
    " \n",
    "#### Subjective Measures\n",
    "\n",
    "As a natural contrast to objective performance measures, subjective metrics provide quantitative values which must be interpreted in order to determine success. These measures typically capture characteristics of recommendations which are not directly related to rating data, but which nonetheless may be very important when a user decides whether or not to follow a suggestion. Two popular measures are:   \n",
    " \n",
    " - **Novelty:** This is a measure of how many under-rated items (not to be confused with poorly-rated ones) are suggested to a user. Exposing individuals to lesser-known items in a catalog is, as we have already discussed, vital to a recommender system's functioning. \n",
    " \n",
    " \n",
    " - **Diversity:** This measurement evaluates the number of different item categories present in a recommendation list given to a user. \n",
    " \n",
    " \n",
    "We're done with the background theory for now, let's go and build something!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case: Producing Book Recommendations \n",
    "\n",
    "To ground our learning in a practical problem, we'll be using the [Goodbooks-10k dataset](http://fastml.com/goodbooks-10k-a-new-dataset-for-book-recommendations/) within this train. \n",
    "\n",
    "[Goodbooks](https://www.goodbooks.io/) is an online book recommendation service which pairs readers up with their next favorite read. The dataset we're using contains information on 10'000 books from the service's catalog, along with ~80'000 reviews generated by site-goers. We'll use this rich information to try our own hand at making recommendations on what good books you (or your friends/family) should read next.\n",
    "\n",
    "\n",
    "### Dataset Overview: Brief EDA\n",
    "\n",
    "We'll be making use of two main files derived from the dataset$^*$;\n",
    " \n",
    " - **Books_with_tags.csv**: This is a file that we've created for the convenience of this train. It contains book_id, title, author, date, etc. data from the original `books.csv` file, along with user tags merged from the `book_tags.csv` and `tags.csv` files. \n",
    " \n",
    " \n",
    " - **Book_ratings.csv**: This is a subset of the `ratings.csv` file, with a field for the title of the books added for convenience. This file contains the important mapping between users and item ratings.\n",
    " \n",
    "$^*$_Full dataset can be found [here](https://www.kaggle.com/zygmunt/goodbooks-10k)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\DELL\\Desktop\\ExploreAI\\academy-content\\.conda\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\DELL\\Desktop\\ExploreAI\\academy-content\\.conda ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "books = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/unsupervised_sprint/books_with_tags.csv')\n",
    "books.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of books in dataset: 10000\n"
     ]
    }
   ],
   "source": [
    "print (f'Number of books in dataset: {books.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>314</td>\n",
       "      <td>1</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince (Harry ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>439</td>\n",
       "      <td>1</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince (Harry ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>588</td>\n",
       "      <td>1</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince (Harry ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1169</td>\n",
       "      <td>1</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince (Harry ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1185</td>\n",
       "      <td>1</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince (Harry ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id                                              title  rating\n",
       "0      314        1  Harry Potter and the Half-Blood Prince (Harry ...       5\n",
       "1      439        1  Harry Potter and the Half-Blood Prince (Harry ...       3\n",
       "2      588        1  Harry Potter and the Half-Blood Prince (Harry ...       5\n",
       "3     1169        1  Harry Potter and the Half-Blood Prince (Harry ...       4\n",
       "4     1185        1  Harry Potter and the Half-Blood Prince (Harry ...       4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_ratings = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/unsupervised_sprint/book_ratings.csv')\n",
    "book_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings in dataset: 79701\n"
     ]
    }
   ],
   "source": [
    "print (f'Number of ratings in dataset: {book_ratings.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a distribution of the ratings given by users. Here we see that readers generally are on the kinder end of the rating spectrum, with a far higher proportion of positive reviews (> 3) being given over negative ones (< 3):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rating in dataset: 3.8616453996813087\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with sns.axes_style('white'):\n",
    "    g = sns.catplot(data=book_ratings, x=\"rating\", y=None, aspect=2.0, kind='count')\n",
    "    g.set_ylabels(\"Total number of ratings\")\n",
    "print (f'Average rating in dataset: {np.mean(book_ratings[\"rating\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's enough spelunking through our data, let's go ahead and actually make a recommendation system. \n",
    "\n",
    "First up is generating recommendations using Content-based filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-based Filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works \n",
    "\n",
    "<br></br>\n",
    "\n",
    "<div align=\"center\" style=\"width: 800px; font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Content_filtering.jpg\"\n",
    "     alt=\"Content-based Filtering\"\n",
    "     style=\"float: center; padding-bottom=0.5em\"\n",
    "     width=800px/>\n",
    "A depiction of the decision process used to recommend items within content-based filtering algorithms.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Content-based Filtering, we seek to make recommendations based on **how similar the properties or features of an item are to other items**. \n",
    "\n",
    "Let's use the image above to help us see how this works. Mpho is an avid reader who has just finished the novel \"The Golden Compass\". Besides the written contents inside this book (item), it has certain attributes or properties which further describe it - such as the author (\"Philip Pullman\"), genre (\"fantasy\"), or target audience (\"young adult\"). These properties are not unique to this novel, as other books also have authors, genres, target audiences, etc. As such, we can compare the properties of different books with the assumption that books which have properties in common (such as author or genre) are similar to one another. We can further **assume that individuals like similar items**. For our example, this means that Mpho, if using content-based filtering to recommend her next book, would have a book such as \"Harry Potter and the Philosopher's Stone\" suggested to her over Anne Frank's \"The Diary of a Young Girl\", as the former novel is far more 'similar' to The Golden Compass.     \n",
    "\n",
    "So let's see how we would implement a system like this in real life."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation \n",
    "\n",
    "Let's implement a simple content filtering-based recommendation algorithm.\n",
    "\n",
    "To start off, we need to gather the various properties of our items so that we can convert them into meaningful features. Following along from our example above, we're going to use the `tag_name` field for each book as a representation of properties such as genre, time-period, and target audience. We're also going to consider the `authors` field, as individuals often enjoy reading novels written by the same author. \n",
    "\n",
    "We start off by creating a new column in our `books` dataframe called `auth_tags`, which contains the above-motivated contents for each item. We additionally create two pandas series objects to help us translate between book titles and indexes of our dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "books['auth_tags'] = (pd.Series(books[['authors', 'tag_name']]\n",
    "                      .fillna('')\n",
    "                      .values.tolist()).str.join(' '))\n",
    "\n",
    "# Convienient indexes to map between book titles and indexes of \n",
    "# the books dataframe\n",
    "titles = books['title']\n",
    "indices = pd.Series(books.index, index=books['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need a mechanism to convert these textual features into a format which enables us to compute their relative similarities to one another.\n",
    "This will allow us to translate our string-based collection of tags and authors into numerical vectors (see [here](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) for an overview of this process which is very similar to [count-based vectorization](https://youtu.be/W9VtEVBdgnQ))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1,2),\n",
    "                     min_df=0, stop_words='english')\n",
    "\n",
    "# Produce a feature matrix, where each row corresponds to a book,\n",
    "# with TF-IDF features as columns \n",
    "tf_authTags_matrix = tf.fit_transform(books['auth_tags'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can compute the similarity between each vector within our matrix. This is done by making use of the `cosine_similarity` function provided to us by `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10000)\n"
     ]
    }
   ],
   "source": [
    "cosine_sim_authTags = cosine_similarity(tf_authTags_matrix, \n",
    "                                        tf_authTags_matrix)\n",
    "print (cosine_sim_authTags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.21246314, 0.25620534, ..., 0.04730311, 0.07394757,\n",
       "        0.01578043],\n",
       "       [0.21246314, 1.        , 0.20308655, ..., 0.04934816, 0.06629237,\n",
       "        0.02173749],\n",
       "       [0.25620534, 0.20308655, 1.        , ..., 0.03131751, 0.03967015,\n",
       "        0.0137797 ],\n",
       "       [0.11415006, 0.16092333, 0.10326477, ..., 0.06834212, 0.07096014,\n",
       "        0.04973093],\n",
       "       [0.11438683, 0.14651929, 0.1160679 , ..., 0.06632025, 0.08923058,\n",
       "        0.03776143]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim_authTags[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting structure is a $10000 \\times 10000$ dense similarity matrix $S^I$, where the value of the entry in the $i^{th}$ row and $j^{th}$ column, $S^I_{i,j}$, corresponds to the similarity of books $i$ and $j$ within our dataset.\n",
    "\n",
    "Using this notation, if $i$ and $j$ are the same number (i.e. all the diagonal entries in $S^I$), then the similarity value is equal to 1 (an item is completely similar to itself).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top-N Recommendations\n",
    "\n",
    "With our content similarity matrix computed, we're now ready to make some recommendations! Let's begin by generating a top-N list of books similar to one which we prompt the system with.    \n",
    "\n",
    "Following along from our earlier algorithmic explanation, we do this by: \n",
    "\n",
    "  1. Select an initial item (book) to generate recommendations from. \n",
    "  2. Extract all the similarity values between the initial item and each other item in the similarity matrix.\n",
    "  3. Sort the resulting values in descending order. \n",
    "  4. Select the top N similarity values, and return the corresponding item details to the user. This is now our simple top-N list.  \n",
    "  \n",
    "We implement this algorithmic process in the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_generate_top_N_recommendations(book_title, N=10):\n",
    "    # Convert the string book title to a numeric index for our \n",
    "    # similarity matrix\n",
    "    b_idx = indices[book_title]\n",
    "    # Extract all similarity values computed with the reference book title\n",
    "    sim_scores = list(enumerate(cosine_sim_authTags[b_idx]))\n",
    "    # Sort the values, keeping a copy of the original index of each value\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    # Select the top-N values for recommendation\n",
    "    sim_scores = sim_scores[1:N]\n",
    "    # Collect indexes \n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "    # Convert the indexes back into titles \n",
    "    return titles.iloc[book_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our function defined, let's test our simple content-based recommender on some sample book titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188     The Lord of the Rings (The Lord of the Rings, ...\n",
       "154            The Two Towers (The Lord of the Rings, #2)\n",
       "160     The Return of the King (The Lord of the Rings,...\n",
       "18      The Fellowship of the Ring (The Lord of the Ri...\n",
       "610              The Silmarillion (Middle-Earth Universe)\n",
       "4975        Unfinished Tales of NÃºmenor and Middle-Earth\n",
       "2308                               The Children of HÃºrin\n",
       "963     J.R.R. Tolkien 4-Book Boxed Set: The Hobbit an...\n",
       "465                             The Hobbit: Graphic Novel\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_generate_top_N_recommendations(\"The Hobbit\", N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352                      Othello\n",
       "769                Julius Caesar\n",
       "124                       Hamlet\n",
       "153                      Macbeth\n",
       "247    A Midsummer Night's Dream\n",
       "838       The Merchant of Venice\n",
       "854                Twelfth Night\n",
       "529       Much Ado About Nothing\n",
       "713                    King Lear\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_generate_top_N_recommendations(\"Romeo and Juliet\", N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86                           Night (The Night Trilogy #1)\n",
       "178                    Angela's Ashes (Frank McCourt, #1)\n",
       "799                                  The Story of My Life\n",
       "1814    Anne Frank Remembered: The Story of the Woman ...\n",
       "512     The Hiding Place: The Triumphant True Story of...\n",
       "6546                        I Have Lived a Thousand Years\n",
       "8027             Anne Frank's Tales from the Secret Annex\n",
       "89                                          The Outsiders\n",
       "603                                     Girl, Interrupted\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_generate_top_N_recommendations(\"The Diary of a Young Girl\", N=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having seen the results of these top-N lists, a couple of observations can be made. \n",
    "\n",
    "- First, our recommendations seem to be strongly centered around the author of the reference book. For example,  other works by Tolkien and Shakespeare are highly recommended when using reference searches for \"The Hobbit\" and \"Romeo and Juliet\" respectively. This could be a natural result of the fact that an author's name is far less common in the dataset than other textual features such as genre. As such, books which share an author will be regarded as being far more similar.  \n",
    "\n",
    "\n",
    " - Second, in cases where the reference author has not written multiple book titles, such as Anne Frank (The Diary of a Young Girl), the recommendations produced are more varied and cover multiple titles in the same or similar genres. \n",
    "\n",
    " \n",
    "Based on these observations, we can ask if in fact the recommendations for \"The Hobbit\" and \"Romeo and Juliet\" are actually any good? After all, a reader who knows of Tolkien and Shakespeare will often already know of other books these authors have written as well. This is where some of the subjective metrics introduced earlier (such as diversity), can be used to penalize these recommendations and help discover better ones. \n",
    "\n",
    "---\n",
    "#### Content filtering: Student Exercise\n",
    "\n",
    "Seeing that we were able to produce more varied recommendations when the author didn't write multiple titles, try to alter the above code cells to calculate similarity only using the `tag_name` field.\n",
    "\n",
    "How does this alteration affect the recommendations produced?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rating Prediction\n",
    "\n",
    "As motivated previously, in some cases we may wish to directly calculate what rating a user _would_ give a book that they haven't read yet. \n",
    "\n",
    "We can modify our content-based filtering algorithm to do this in the following manner: \n",
    "\n",
    "   1. Select a reference user from the database and a reference item (book) they have _not_ rated. \n",
    "   2. For the user, gather the similarity values between the reference item and each item the user _has_ rated. \n",
    "   3. Sort the gathered similarity values in descending order. \n",
    "   4. Select the $k$ highest similarity values which are above a given threshold value, creating a collection $K$. \n",
    "   5. Compute a weighted average rating from these values, which is the sum of the similarity values of each item multiplied by its assigned user-rating, divided by the sum of the similarity values. This can be expressed in formula as:\n",
    "   \n",
    "   $$ \\hat{R}_{ju} = \\frac{\\sum_{i \\in K} s_{ij} \\times r_{iu}}{\\sum_{i \\in K} s_{ij}}   $$\n",
    "   \n",
    "   where $\\hat{R}_{ju}$ is the weighted average computed for the reference item $j$ and reference user $u$, $K$ is the collection of items, $s_{ij}$ is the similarity computed between items $i$ and $j$, and $r_{iu}$ is the known rating user $u$ has given item $i$.\n",
    "   6. We return the weighted average $\\hat{R}_{ju}$ as the prediction for our reference item.\n",
    "   \n",
    "   \n",
    "We implement this algorithmic process in the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_generate_rating_estimate(book_title, user, rating_data, k=20, threshold=0.0):\n",
    "    # Convert the book title to a numeric index for our \n",
    "    # similarity matrix\n",
    "    b_idx = indices[book_title]\n",
    "    neighbors = [] # <-- Stores our collection of similarity values \n",
    "     \n",
    "    # Gather the similarity ratings between each book the user has rated\n",
    "    # and the reference book \n",
    "    for index, row in rating_data[rating_data['user_id']==user].iterrows():\n",
    "        sim = cosine_sim_authTags[b_idx-1, indices[row['title']]-1]\n",
    "        neighbors.append((sim, row['rating']))\n",
    "    # Select the top-N values from our collection\n",
    "    k_neighbors = heapq.nlargest(k, neighbors, key=lambda t: t[0])\n",
    "\n",
    "    # Compute the weighted average using similarity scores and \n",
    "    # user item ratings. \n",
    "    simTotal, weightedSum = 0, 0\n",
    "    for (simScore, rating) in k_neighbors:\n",
    "        # Ensure that similarity ratings are above a given threshold\n",
    "        if (simScore > threshold):\n",
    "            simTotal += simScore\n",
    "            weightedSum += simScore * rating\n",
    "    try:\n",
    "        predictedRating = weightedSum / simTotal\n",
    "    except ZeroDivisionError:\n",
    "        # Cold-start problem - No ratings given by user. \n",
    "        # We use the average rating for the reference item as a proxy in this case \n",
    "        predictedRating = np.mean(rating_data[rating_data['title']==book_title]['rating'])\n",
    "    return predictedRating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our algorithm defined, let's quickly test it out to see some results. \n",
    "\n",
    "To help us get a sense of the relevance and accuracy of these ratings, we select a lucky user (number 314) and consider their historical data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>401</td>\n",
       "      <td>314</td>\n",
       "      <td>6</td>\n",
       "      <td>Harry Potter and the Goblet of Fire (Harry Pot...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>314</td>\n",
       "      <td>29</td>\n",
       "      <td>The Mother Tongue: English and How It Got That...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>314</td>\n",
       "      <td>30</td>\n",
       "      <td>J.R.R. Tolkien 4-Book Boxed Set: The Hobbit an...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>314</td>\n",
       "      <td>36</td>\n",
       "      <td>The Lord of the Rings: Weapons and Warfare</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>314</td>\n",
       "      <td>98</td>\n",
       "      <td>What to Expect the First Year (What to Expect)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>314</td>\n",
       "      <td>105</td>\n",
       "      <td>Chapterhouse: Dune (Dune Chronicles #6)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2501</td>\n",
       "      <td>314</td>\n",
       "      <td>106</td>\n",
       "      <td>Dune Messiah (Dune Chronicles #2)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  book_id                                              title  \\\n",
       "401       314        6  Harry Potter and the Goblet of Fire (Harry Pot...   \n",
       "1500      314       29  The Mother Tongue: English and How It Got That...   \n",
       "1600      314       30  J.R.R. Tolkien 4-Book Boxed Set: The Hobbit an...   \n",
       "1900      314       36         The Lord of the Rings: Weapons and Warfare   \n",
       "2300      314       98     What to Expect the First Year (What to Expect)   \n",
       "2400      314      105            Chapterhouse: Dune (Dune Chronicles #6)   \n",
       "2501      314      106                  Dune Messiah (Dune Chronicles #2)   \n",
       "\n",
       "      rating  \n",
       "401        5  \n",
       "1500       3  \n",
       "1600       4  \n",
       "1900       4  \n",
       "2300       3  \n",
       "2400       3  \n",
       "2501       4  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset of ratings from user 314\n",
    "book_ratings[book_ratings['user_id'] == 314][3:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first generate some ratings for books which user 314 has already rated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title - The Lord of the Rings: Weapons and Warfare\n",
      "---\n",
      "Actual rating: \t\t 4\n",
      "Predicted rating: \t 3.82672277262443\n"
     ]
    }
   ],
   "source": [
    "title = \"The Lord of the Rings: Weapons and Warfare\"\n",
    "actual_rating = book_ratings[(book_ratings['user_id'] == 314) & (book_ratings['title'] == title)]['rating'].values[0]\n",
    "pred_rating = content_generate_rating_estimate(book_title=title, user=314, rating_data=book_ratings)\n",
    "print (f\"Title - {title}\")\n",
    "print (\"---\")\n",
    "print (f\"Actual rating: \\t\\t {actual_rating}\")\n",
    "print (f\"Predicted rating: \\t {pred_rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title - Survival in Auschwitz\n",
      "---\n",
      "Actual rating: \t\t 2\n",
      "Predicted rating: \t 2.7984141604453825\n"
     ]
    }
   ],
   "source": [
    "title = \"Survival in Auschwitz\"\n",
    "actual_rating = book_ratings[(book_ratings['user_id'] == 314) & (book_ratings['title'] == title)]['rating'].values[0]\n",
    "pred_rating = content_generate_rating_estimate(book_title=title, user=314, rating_data=book_ratings)\n",
    "print (f\"Title - {title}\")\n",
    "print (\"---\")\n",
    "print (f\"Actual rating: \\t\\t {actual_rating}\")\n",
    "print (f\"Predicted rating: \\t {pred_rating}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do this again, but now for similar titles which have not been rated:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title - The Hobbit\n",
      "---\n",
      "Actual rating: \t\t ?\n",
      "Predicted rating: \t 3.5748388697863294\n"
     ]
    }
   ],
   "source": [
    "title = \"The Hobbit\"\n",
    "pred_rating = content_generate_rating_estimate(book_title=title, user=314, rating_data=book_ratings)\n",
    "print (f\"Title - {title}\")\n",
    "print (\"---\")\n",
    "print (f\"Actual rating: \\t\\t ?\")\n",
    "print (f\"Predicted rating: \\t {pred_rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title - Dune (Dune Chronicles #1)\n",
      "---\n",
      "Actual rating: \t\t ?\n",
      "Predicted rating: \t 3.7612070634075323\n"
     ]
    }
   ],
   "source": [
    "title = \"Dune (Dune Chronicles #1)\"\n",
    "pred_rating = content_generate_rating_estimate(book_title=title, user=314, rating_data=book_ratings)\n",
    "print (f\"Title - {title}\")\n",
    "print (\"---\")\n",
    "print (f\"Actual rating: \\t\\t ?\")\n",
    "print (f\"Predicted rating: \\t {pred_rating}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above results, our content-based ratings seem to be pretty good - being out by than less 1 rating point per known prediction! While we can't make the same judgement for the predicted ratings of the unseen books, they are close to known book ratings which are similar in nature, which is a promising sign.\n",
    "\n",
    "That's enough of content based filtering. In the next part of this train, namely Introduction to Recommender systems: Part 2, we will be moving on to the second type of recommender system method: collaborative filtering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We covered alot of good ground in this train by identifying the building blocks of recommender systems; items (things) and users (people). We've learned how recommender algorithms fundamentally use similarity as a mechanism to compare these items and users, with item-item similarity being represented by the content-based filtering method. We went on to review the content-based filtering method both theoretically and  practically through code implementation. \n",
    "\n",
    "Next up we will be doing some deep diving into collaborative filtering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "Links to additional resources to help with the understanding of concepts presented in the train:\n",
    "\n",
    "- [Intro to Recommender Systems](https://www.youtube.com/watch?v=Eeg1DEeWUjA&feature=youtu.be)\n",
    "- [Advanced Recommender System Metrics](https://wiki.epfl.ch/edicpublic/documents/Candidacy%20exam/Evaluation.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
