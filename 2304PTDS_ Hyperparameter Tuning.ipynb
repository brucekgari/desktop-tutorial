{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b13b0a43",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "**In this webinar:**\n",
    "1. Hyperparameter tuning\n",
    "2. Some commonly-used hyperparameters\n",
    "3. GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36bc96b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Objectives:**\n",
    "- Understand the value of hyperparameter tuning in model optimisation\n",
    "- Understand the code application of GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff455f2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "- Parameters that specify details of the model's learning process \n",
    "- Hyperparameters are usually specified before the training process\n",
    "- Values are not learned from the data\n",
    "- Finding **optimal** values can vastly improve model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4566d7c9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Some common hyperparameters\n",
    "\n",
    "### Logistic Regression\n",
    "\n",
    "`penalty`: {‘l1’, ‘l2’, ‘elasticnet’, None}, default=’l2’\n",
    "\n",
    "- Specify the norm of the penalty\n",
    "\n",
    "`C` positive float, default=1.0\n",
    "\n",
    "- Inverse of regularization strength. Smaller values specify stronger regularization.\n",
    "\n",
    "`multi_class`: {‘auto’, ‘ovr’, ‘multinomial’}, default=’auto’\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74567a2e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Decision Tree Classifier\n",
    "\n",
    "`max_depth`: int, default=None\n",
    "\n",
    "- The maximum depth of the tree\n",
    "\n",
    "`min_samples_leaf`: int or float, default=1\n",
    "\n",
    "- The minimum number of samples required to be at a leaf node\n",
    "\n",
    "`max_features`: int, float or {“auto”, “sqrt”, “log2”}, default=None\n",
    "\n",
    "- The number of features to consider when looking for the best split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be46979",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://1329420134-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-LagOeJ2nL90MQERwhxy%2F-LjmGR4-Zkpsp-CXV3zt%2F-Lk-zlkug29fjZ6T44mL%2Fimage.png?alt=media&token=f775f1ce-2256-4172-af1b-e66e916ec127)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d39997d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Random Forest Classifier\n",
    "\n",
    "`n_estimators`: int, default=100\n",
    "\n",
    "- The number of trees in the forest\n",
    "\n",
    "`max_depth`: int, default=None\n",
    "\n",
    "- The maximum depth of the tree\n",
    "\n",
    "`bootstrap`: bool, default=True\n",
    "\n",
    "- Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c3207d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://miro.medium.com/v2/resize:fit:1358/1*i69vGs4AfhdhDUOlaPVLSA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c228b311",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### K Nearest Neighbor Classifier\n",
    "\n",
    "`n_neighbors`: int, default=5\n",
    "\n",
    "- Number of neighbors to use by default for kneighbors queries\n",
    "\n",
    "`weights`: {‘uniform’, ‘distance’}, callable or None, default=’uniform’\n",
    "\n",
    "- Weight function used in prediction\n",
    "\n",
    "`metric`: str or callable, default=’minkowski’\n",
    "\n",
    "- Metric to use for distance computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76753589",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://www.researchgate.net/publication/331424423/figure/fig1/AS:732056359297024@1551547245072/Example-on-KNN-classifier.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed5b289",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "**Bonus**: Check out the documentation for [SVC]() and [Naive Bayes]() classifiers to explore the parameters that can be tuned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba11d6ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tuning some hyperparameters - an example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c203ad54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    " \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "021eb6cd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>kids like story BUT while i really wanted a bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Bought this used and it came in great conditio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Every story and book about Corduroy is Fantast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>I purchased this book for my first grade class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Having spent numerous years in an elementary s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall                                         reviewText\n",
       "0        4  kids like story BUT while i really wanted a bo...\n",
       "1        4  Bought this used and it came in great conditio...\n",
       "2        5  Every story and book about Corduroy is Fantast...\n",
       "3        5  I purchased this book for my first grade class...\n",
       "4        5  Having spent numerous years in an elementary s..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews = pd.read_csv('amazon_reviews.csv')\n",
    "df_reviews = df_reviews.drop(columns = 'Unnamed: 0').dropna() \n",
    "\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdec65e0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's look at the distribution of ratings in our data\n",
    "\n",
    "ratings = df_reviews[['overall', 'reviewText']].groupby('overall').count()\n",
    "\n",
    "ratings.sort_values('overall', ascending = False).plot(kind = 'bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defcf360",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Try out some more NLP steps to see if it improves any of them models' performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6099d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "# Un-comment some of the below code to help you\n",
    "\n",
    "#import string\n",
    "#print(string.punctuation)\n",
    "\n",
    "# Try creating a function for this and applying it to the dataframe!:\n",
    "\n",
    "#def punctuation_remover(email):\n",
    "#    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92206709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenise the data\n",
    "# Un-comment some of the below code to help you\n",
    "\n",
    "#from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "#tokeniser = ...\n",
    "#df['column'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f84ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatise the words\n",
    "# Un-comment some of the below code to help you\n",
    "\n",
    "\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "#import nltk\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "#lemmatizer = ...\n",
    "# apply it to your dataframe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9b1498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the individual words back together to form sentences again, so they can be passed through the Vectoriser\n",
    "\n",
    "# Hint: use the .join() method to help you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be88fa57",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Create a CountVectorizer instance \n",
    "vectorizer = CountVectorizer(stop_words = 'english')\n",
    "\n",
    "\n",
    "# Fit and transform the documents, set up X and y\n",
    "X = vectorizer.fit_transform(df_reviews['reviewText'])\n",
    "y = np.array(df_reviews['overall'])\n",
    "\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c525fab",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's say we want to see the difference in performance of four random forest models\n",
    "# with a different number of estimators:\n",
    "\n",
    "rf1 = RandomForestClassifier(n_estimators = 10, random_state = 27)\n",
    "\n",
    "rf2 = RandomForestClassifier(n_estimators = 50, random_state = 27)\n",
    "\n",
    "rf3 = RandomForestClassifier(n_estimators = 75, random_state = 27)\n",
    "\n",
    "rf4 = RandomForestClassifier(n_estimators = 100, random_state = 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "581a6895",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting RF model with n_estimators = 10\n",
      "Fitting RF model with n_estimators = 50\n",
      "Fitting RF model with n_estimators = 75\n",
      "Fitting RF model with n_estimators = 100\n"
     ]
    }
   ],
   "source": [
    "# that was a lot of repetition...how can we make it easier?\n",
    "\n",
    "est = [10, 50, 75, 100]\n",
    "\n",
    "results = []\n",
    "\n",
    "for x in est:\n",
    "    print(\"Fitting RF model with n_estimators = {:d}\".format(x))\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators = x, random_state = 27)\n",
    "    \n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_preds = rf.predict(X_test)\n",
    "    \n",
    "    f1_test = metrics.f1_score(y_test, y_preds, average='weighted')\n",
    "    \n",
    "    results.append([x, f1_test])\n",
    "    \n",
    "results = pd.DataFrame(results, columns=['n_estimators', 'f1 score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8e1b686",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.681193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0.673331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>0.670630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>0.672813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  f1 score\n",
       "0            10  0.681193\n",
       "1            50  0.673331\n",
       "2            75  0.670630\n",
       "3           100  0.672813"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50eb6e91",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1 2\n",
      "10 1 3\n",
      "10 1 4\n",
      "10 1 5\n",
      "10 3 2\n",
      "10 3 3\n",
      "10 3 4\n",
      "10 3 5\n",
      "10 5 2\n",
      "10 5 3\n",
      "10 5 4\n",
      "10 5 5\n",
      "10 7 2\n",
      "10 7 3\n",
      "10 7 4\n",
      "10 7 5\n",
      "50 1 2\n",
      "50 1 3\n",
      "50 1 4\n",
      "50 1 5\n",
      "50 3 2\n",
      "50 3 3\n",
      "50 3 4\n",
      "50 3 5\n",
      "50 5 2\n",
      "50 5 3\n",
      "50 5 4\n",
      "50 5 5\n",
      "50 7 2\n",
      "50 7 3\n",
      "50 7 4\n",
      "50 7 5\n",
      "75 1 2\n",
      "75 1 3\n",
      "75 1 4\n",
      "75 1 5\n",
      "75 3 2\n",
      "75 3 3\n",
      "75 3 4\n",
      "75 3 5\n",
      "75 5 2\n",
      "75 5 3\n",
      "75 5 4\n",
      "75 5 5\n",
      "75 7 2\n",
      "75 7 3\n",
      "75 7 4\n",
      "75 7 5\n",
      "100 1 2\n",
      "100 1 3\n",
      "100 1 4\n",
      "100 1 5\n",
      "100 3 2\n",
      "100 3 3\n",
      "100 3 4\n",
      "100 3 5\n",
      "100 5 2\n",
      "100 5 3\n",
      "100 5 4\n",
      "100 5 5\n",
      "100 7 2\n",
      "100 7 3\n",
      "100 7 4\n",
      "100 7 5\n"
     ]
    }
   ],
   "source": [
    "# But now what if we also want to play around with the max_depth? [1, 3, 5, 7]\n",
    "# We could do the same as above, but we're going to have to do so many different combos\n",
    "# How many combos?\n",
    "\n",
    "depths = [1, 3, 5, 7]\n",
    "max_features = [2, 3, 4, 5]\n",
    "\n",
    "for x in est: \n",
    "    for y in depths:\n",
    "        for z in max_features:\n",
    "            print(x, y, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08095ec4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Instead, let's automate this with GridSearchCV!\n",
    "\n",
    "We can automate the process without having to write so much code to go through each set of hyperparameters, or set up a very intricate set of for-loops to go through combinations of different hyperparameters. sklearn's GridSearchCV does all this for us!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c3b017",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "GridSearchCV works in the following way:\n",
    "- You (the user) define a set of hyperparameters to tune, and the values you want to test\n",
    "- Define a score function to evaluate the performance of each hyperparameter combination\n",
    "- Perform a grid search over all possible combinations of hyperparameters and evaluate with cross validation\n",
    "- Select the best hyperparameter combination based on the evaluation metric specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f01fea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cd28e2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Syntax for GridSearchCV:\n",
    "\n",
    "```python\n",
    "\n",
    "GridSearchCV(estimator/model, param_grid, scoring = metric, cv = 5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b0f1c5",
   "metadata": {},
   "source": [
    "*  **estimator** is your model\n",
    "\n",
    "\n",
    "*  **param_grid** is where you can set up all the hyperparameter values you want to try out. It is written in the form of a dictionary:\n",
    "\n",
    "```python\n",
    "{'hyperparam_1': [values],\n",
    "\n",
    "'hyperparam_2': [values]}\n",
    "```\n",
    "\n",
    "\n",
    "*  **scoring** is where you define the metric you want to evaluate your model's performance on\n",
    "\n",
    "\n",
    "*  **cv** is where you can define how many cross-fold validations you want GridSearch to use when deciding on the best model and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbc71774",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 10}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'n_estimators': [10, 50, 75, 100]}\n",
    "\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(random_state = 27), \n",
    "                       param_grid, \n",
    "                       scoring = 'f1_weighted', \n",
    "                       cv = 3)\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "grid_rf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7976a24",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now let's try adding in max_features to see what the best combination is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e000af9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'sqrt', 'n_estimators': 10}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = [\"sqrt\", \"log2\"]\n",
    "\n",
    "param_grid = {'n_estimators': [10, 50, 75, 100], \n",
    "              'max_features': [\"sqrt\", \"log2\"]}\n",
    "\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(random_state = 27), \n",
    "                       param_grid, \n",
    "                       scoring = 'f1_weighted', \n",
    "                       cv = 3)\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "grid_rf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4c8dc4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Once we've done all we want to with GridSearchCV and we've got a set of our best performing parameters, GridSearchCV actually stores these for us to immediately make predictions with if we need to!:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d65b0a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.09      0.15        45\n",
      "           2       0.33      0.11      0.16        55\n",
      "           3       0.21      0.10      0.14       109\n",
      "           4       0.32      0.17      0.22       299\n",
      "           5       0.78      0.93      0.85      1492\n",
      "\n",
      "    accuracy                           0.73      2000\n",
      "   macro avg       0.44      0.28      0.30      2000\n",
      "weighted avg       0.67      0.73      0.68      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_preds = grid_rf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, grid_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354ca9bd",
   "metadata": {},
   "source": [
    "We can have a look at all of the resutls from the GridSearch using the `.cv_results_` method, put into a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e91cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_results = pd.DataFrame(grid_rf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c26efe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.860211</td>\n",
       "      <td>0.033952</td>\n",
       "      <td>0.017174</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 'sqrt', 'n_estimators': 10}</td>\n",
       "      <td>0.677590</td>\n",
       "      <td>0.671922</td>\n",
       "      <td>0.681914</td>\n",
       "      <td>0.677142</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.315842</td>\n",
       "      <td>0.108015</td>\n",
       "      <td>0.075932</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 'sqrt', 'n_estimators': 50}</td>\n",
       "      <td>0.673586</td>\n",
       "      <td>0.674166</td>\n",
       "      <td>0.663366</td>\n",
       "      <td>0.670373</td>\n",
       "      <td>0.004960</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.467961</td>\n",
       "      <td>0.104287</td>\n",
       "      <td>0.111313</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>75</td>\n",
       "      <td>{'max_features': 'sqrt', 'n_estimators': 75}</td>\n",
       "      <td>0.673951</td>\n",
       "      <td>0.675124</td>\n",
       "      <td>0.661790</td>\n",
       "      <td>0.670288</td>\n",
       "      <td>0.006028</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.557406</td>\n",
       "      <td>0.047571</td>\n",
       "      <td>0.148765</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 'sqrt', 'n_estimators': 100}</td>\n",
       "      <td>0.668871</td>\n",
       "      <td>0.674705</td>\n",
       "      <td>0.664134</td>\n",
       "      <td>0.669237</td>\n",
       "      <td>0.004323</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.105796</td>\n",
       "      <td>0.016654</td>\n",
       "      <td>0.026841</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 'log2', 'n_estimators': 10}</td>\n",
       "      <td>0.667364</td>\n",
       "      <td>0.669414</td>\n",
       "      <td>0.661788</td>\n",
       "      <td>0.666189</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.598654</td>\n",
       "      <td>0.232837</td>\n",
       "      <td>0.122998</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 'log2', 'n_estimators': 50}</td>\n",
       "      <td>0.659345</td>\n",
       "      <td>0.663014</td>\n",
       "      <td>0.654040</td>\n",
       "      <td>0.658800</td>\n",
       "      <td>0.003684</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.291831</td>\n",
       "      <td>0.098999</td>\n",
       "      <td>0.182493</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>log2</td>\n",
       "      <td>75</td>\n",
       "      <td>{'max_features': 'log2', 'n_estimators': 75}</td>\n",
       "      <td>0.660250</td>\n",
       "      <td>0.661240</td>\n",
       "      <td>0.652586</td>\n",
       "      <td>0.658026</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.230484</td>\n",
       "      <td>0.391035</td>\n",
       "      <td>0.247425</td>\n",
       "      <td>0.003651</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 'log2', 'n_estimators': 100}</td>\n",
       "      <td>0.658979</td>\n",
       "      <td>0.661127</td>\n",
       "      <td>0.651326</td>\n",
       "      <td>0.657144</td>\n",
       "      <td>0.004207</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.860211      0.033952         0.017174        0.000587   \n",
       "1       4.315842      0.108015         0.075932        0.000417   \n",
       "2       6.467961      0.104287         0.111313        0.001198   \n",
       "3       8.557406      0.047571         0.148765        0.000764   \n",
       "4       1.105796      0.016654         0.026841        0.000044   \n",
       "5       5.598654      0.232837         0.122998        0.001346   \n",
       "6       8.291831      0.098999         0.182493        0.001789   \n",
       "7      11.230484      0.391035         0.247425        0.003651   \n",
       "\n",
       "  param_max_features param_n_estimators  \\\n",
       "0               sqrt                 10   \n",
       "1               sqrt                 50   \n",
       "2               sqrt                 75   \n",
       "3               sqrt                100   \n",
       "4               log2                 10   \n",
       "5               log2                 50   \n",
       "6               log2                 75   \n",
       "7               log2                100   \n",
       "\n",
       "                                          params  split0_test_score  \\\n",
       "0   {'max_features': 'sqrt', 'n_estimators': 10}           0.677590   \n",
       "1   {'max_features': 'sqrt', 'n_estimators': 50}           0.673586   \n",
       "2   {'max_features': 'sqrt', 'n_estimators': 75}           0.673951   \n",
       "3  {'max_features': 'sqrt', 'n_estimators': 100}           0.668871   \n",
       "4   {'max_features': 'log2', 'n_estimators': 10}           0.667364   \n",
       "5   {'max_features': 'log2', 'n_estimators': 50}           0.659345   \n",
       "6   {'max_features': 'log2', 'n_estimators': 75}           0.660250   \n",
       "7  {'max_features': 'log2', 'n_estimators': 100}           0.658979   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.671922           0.681914         0.677142        0.004092   \n",
       "1           0.674166           0.663366         0.670373        0.004960   \n",
       "2           0.675124           0.661790         0.670288        0.006028   \n",
       "3           0.674705           0.664134         0.669237        0.004323   \n",
       "4           0.669414           0.661788         0.666189        0.003223   \n",
       "5           0.663014           0.654040         0.658800        0.003684   \n",
       "6           0.661240           0.652586         0.658026        0.003867   \n",
       "7           0.661127           0.651326         0.657144        0.004207   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  \n",
       "1                2  \n",
       "2                3  \n",
       "3                4  \n",
       "4                5  \n",
       "5                6  \n",
       "6                7  \n",
       "7                8  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa61e86",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "GridSeachCV can be a very useful tool for us to optimise our model and experiment with multiple parameters in one go, without having to type out a large amount of code. What is important to note though is that the more we are adding to our GridSearch, the longer it may take to run!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834d9e1a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02842a8a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercises!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26783b56",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. True or False: GridSearch can only optimise for one hyperparameter at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89503a72",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "2. What does the `n_neighbors` hyperparameter mean in a KNN model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a703f52",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "3. What is the difference between upsampling and downsampling?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5842afa4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "4. Can we specify the hyperparameter C to be -1.00 with a Logistic Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0505c1d6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "5. How does K-Fold validation allow us to evaluate our model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e9515c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "6. True or False: Backward stepwise selection starts with an empty set of features and iteratively adds the most significant variable until a criterion is met"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c22cd94",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e4aecb",
   "metadata": {},
   "source": [
    "## Answers below!\n",
    "\n",
    "1. False - we can specifiy values for multiple parameters to search through with GridSearch, using our parameter grid (param_grid)\n",
    "\n",
    "\n",
    "2. `n_neighbors` allows us to specify how many datapoints we want the model to identify as 'nearest neighbors' to use in order to classify our new data point into a class\n",
    "\n",
    "\n",
    "3. Upsampling increases the size of a smaller class through sampling and duplication, downsampling decreases the size of a larger class through sampling\n",
    "\n",
    "\n",
    "4. No we cannot - the value of C needs to be a **positive** float\n",
    "\n",
    "\n",
    "5. K-Fold validation tries different train/test splits of our data. It splits our training data into K 'folds', and each 'fold' is given a chance at being the holdout group (X_test) that we evaluate our model's performance on. The performance across these different folds is then examined to see how consistent our model is performing across different holdout groups. Normally, the mean and standard deviation of our evaluation metric is taken across these K folds to give us an average score.\n",
    "\n",
    "\n",
    "6. False - backwards stepwise selection starts with all features included in the model, and iteratively removes the least significant or important variable one at a time, until we reach a criterion or peak model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b842a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
